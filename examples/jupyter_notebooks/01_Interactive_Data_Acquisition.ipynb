{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2663ea1",
   "metadata": {},
   "source": [
    "# Brain-Forge Interactive Data Acquisition\n",
    "\n",
    "Welcome to the Brain-Forge interactive data acquisition tutorial! This notebook demonstrates the multi-modal brain data acquisition capabilities of the Brain-Forge platform.\n",
    "\n",
    "## What You'll Learn:\n",
    "- How to set up and configure multi-modal brain sensors\n",
    "- Real-time data streaming with microsecond precision\n",
    "- Quality monitoring and artifact detection\n",
    "- Multi-device synchronization techniques\n",
    "- Interactive visualization of live brain data\n",
    "\n",
    "## Hardware Components:\n",
    "- **OPM Helmet**: 306-channel magnetometer array for magnetic field detection\n",
    "- **Kernel Optical Helmet**: Flow/Flux helmets for hemodynamic imaging\n",
    "- **Accelerometer Array**: 3-axis motion tracking for artifact compensation\n",
    "\n",
    "Let's get started! üß†‚ö°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from time import time, sleep\n",
    "import threading\n",
    "from collections import deque\n",
    "\n",
    "# Add Brain-Forge source to path\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent / 'src'))\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üß† Brain-Forge libraries loaded successfully!\")\n",
    "print(\"üìö Interactive widgets ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52dc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Brain-Forge modules\n",
    "try:\n",
    "    from core.logger import get_logger\n",
    "    from hardware.omp_helmet import OMPHelmets\n",
    "    from hardware.kernel_optical import KernelOpticalHelmet\n",
    "    from hardware.accelerometer import AccelerometerArray\n",
    "    from acquisition.stream_manager import StreamManager\n",
    "    from core.config import BrainForgeConfig\n",
    "    \n",
    "    logger = get_logger(__name__)\n",
    "    print(\"‚úÖ Brain-Forge modules imported successfully!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Import warning: {e}\")\n",
    "    print(\"üìù Running in simulation mode...\")\n",
    "    \n",
    "    # Create mock classes for demonstration\n",
    "    class MockHardware:\n",
    "        def __init__(self, config):\n",
    "            self.config = config\n",
    "            self.running = False\n",
    "            \n",
    "        def start(self):\n",
    "            self.running = True\n",
    "            \n",
    "        def stop(self):\n",
    "            self.running = False\n",
    "            \n",
    "        def get_data(self):\n",
    "            return np.random.randn(64, 100) if self.running else None\n",
    "    \n",
    "    OMPHelmets = MockHardware\n",
    "    KernelOpticalHelmet = MockHardware\n",
    "    AccelerometerArray = MockHardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61e6dd",
   "metadata": {},
   "source": [
    "## 1. Hardware Configuration\n",
    "\n",
    "First, let's configure our hardware setup. Brain-Forge supports multiple sensor modalities for comprehensive brain monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive hardware configuration\n",
    "def create_hardware_config():\n",
    "    \"\"\"Create interactive hardware configuration panel\"\"\"\n",
    "    \n",
    "    # OMP Helmet settings\n",
    "    omp_channels = widgets.IntSlider(\n",
    "        value=306, min=64, max=512, step=1,\n",
    "        description='OMP Channels:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    omp_rate = widgets.IntSlider(\n",
    "        value=1000, min=250, max=2000, step=250,\n",
    "        description='Sampling Rate (Hz):', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Kernel Optical settings\n",
    "    optical_channels = widgets.IntSlider(\n",
    "        value=64, min=32, max=128, step=32,\n",
    "        description='Optical Channels:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    optical_wavelengths = widgets.SelectMultiple(\n",
    "        options=[650, 780, 850],\n",
    "        value=[780, 850],\n",
    "        description='Wavelengths (nm):',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Accelerometer settings\n",
    "    accel_range = widgets.Dropdown(\n",
    "        options=[2, 4, 8, 16],\n",
    "        value=8,\n",
    "        description='Accel Range (¬±g):',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Create accordion for organized display\n",
    "    accordion = widgets.Accordion(children=[\n",
    "        widgets.VBox([omp_channels, omp_rate]),\n",
    "        widgets.VBox([optical_channels, optical_wavelengths]),\n",
    "        widgets.VBox([accel_range])\n",
    "    ])\n",
    "    \n",
    "    accordion.set_title(0, 'üß≤ OMP Helmet')\n",
    "    accordion.set_title(1, 'üî¥ Kernel Optical')\n",
    "    accordion.set_title(2, 'üìê Accelerometer')\n",
    "    \n",
    "    return accordion, {\n",
    "        'omp_channels': omp_channels,\n",
    "        'omp_rate': omp_rate,\n",
    "        'optical_channels': optical_channels,\n",
    "        'optical_wavelengths': optical_wavelengths,\n",
    "        'accel_range': accel_range\n",
    "    }\n",
    "\n",
    "# Display configuration panel\n",
    "config_panel, config_widgets = create_hardware_config()\n",
    "display(config_panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hardware based on configuration\n",
    "def initialize_hardware():\n",
    "    \"\"\"Initialize hardware with current configuration\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        'omp': {\n",
    "            'n_channels': config_widgets['omp_channels'].value,\n",
    "            'sampling_rate': config_widgets['omp_rate'].value,\n",
    "            'sensitivity': 10e-15  # fT/‚àöHz\n",
    "        },\n",
    "        'optical': {\n",
    "            'n_channels': config_widgets['optical_channels'].value,\n",
    "            'wavelengths': list(config_widgets['optical_wavelengths'].value),\n",
    "            'sampling_rate': 100  # Hz\n",
    "        },\n",
    "        'accelerometer': {\n",
    "            'range': config_widgets['accel_range'].value,\n",
    "            'resolution': 16,  # bits\n",
    "            'sampling_rate': 1000  # Hz\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Initialize hardware\n",
    "    try:\n",
    "        omp_helmet = OMPHelmets(config['omp'])\n",
    "        optical_helmet = KernelOpticalHelmet(config['optical'])\n",
    "        accelerometer = AccelerometerArray(config['accelerometer'])\n",
    "        \n",
    "        print(\"üîß Hardware initialized successfully!\")\n",
    "        print(f\"   üß≤ OMP: {config['omp']['n_channels']} channels @ {config['omp']['sampling_rate']} Hz\")\n",
    "        print(f\"   üî¥ Optical: {config['optical']['n_channels']} channels, wavelengths: {config['optical']['wavelengths']} nm\")\n",
    "        print(f\"   üìê Accelerometer: ¬±{config['accelerometer']['range']}g range\")\n",
    "        \n",
    "        return omp_helmet, optical_helmet, accelerometer, config\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Hardware initialization error: {e}\")\n",
    "        return None, None, None, config\n",
    "\n",
    "# Initialize button\n",
    "init_button = widgets.Button(description=\"Initialize Hardware\", button_style='success')\n",
    "hardware_status = widgets.Output()\n",
    "\n",
    "def on_init_click(b):\n",
    "    with hardware_status:\n",
    "        clear_output(wait=True)\n",
    "        global omp_helmet, optical_helmet, accelerometer, hw_config\n",
    "        omp_helmet, optical_helmet, accelerometer, hw_config = initialize_hardware()\n",
    "\n",
    "init_button.on_click(on_init_click)\n",
    "\n",
    "display(init_button, hardware_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a660de32",
   "metadata": {},
   "source": [
    "## 2. Real-Time Data Streaming\n",
    "\n",
    "Now let's start streaming data from all sensors simultaneously with microsecond-precision synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time data streaming class\n",
    "class RealTimeStreamer:\n",
    "    def __init__(self, omp, optical, accel):\n",
    "        self.omp = omp\n",
    "        self.optical = optical\n",
    "        self.accel = accel\n",
    "        self.running = False\n",
    "        \n",
    "        # Data buffers\n",
    "        self.data_buffers = {\n",
    "            'omp': deque(maxlen=1000),\n",
    "            'optical': deque(maxlen=1000),\n",
    "            'accel': deque(maxlen=1000),\n",
    "            'timestamps': deque(maxlen=1000)\n",
    "        }\n",
    "        \n",
    "    def start_streaming(self):\n",
    "        \"\"\"Start real-time data acquisition\"\"\"\n",
    "        if self.omp is None:\n",
    "            print(\"‚ùå Hardware not initialized!\")\n",
    "            return\n",
    "            \n",
    "        self.running = True\n",
    "        self.omp.start()\n",
    "        self.optical.start()\n",
    "        self.accel.start()\n",
    "        \n",
    "        # Start data collection thread\n",
    "        self.thread = threading.Thread(target=self._collect_data)\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "        \n",
    "        print(\"üöÄ Real-time streaming started!\")\n",
    "        \n",
    "    def stop_streaming(self):\n",
    "        \"\"\"Stop data acquisition\"\"\"\n",
    "        self.running = False\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join(timeout=1.0)\n",
    "            \n",
    "        if self.omp:\n",
    "            self.omp.stop()\n",
    "            self.optical.stop()\n",
    "            self.accel.stop()\n",
    "            \n",
    "        print(\"üõë Streaming stopped\")\n",
    "        \n",
    "    def _collect_data(self):\n",
    "        \"\"\"Data collection loop\"\"\"\n",
    "        while self.running:\n",
    "            timestamp = time()\n",
    "            \n",
    "            # Collect from all sensors\n",
    "            try:\n",
    "                omp_data = self.omp.get_data()\n",
    "                optical_data = self.optical.get_data()\n",
    "                accel_data = self.accel.get_data()\n",
    "                \n",
    "                # Process and buffer data\n",
    "                if omp_data is not None:\n",
    "                    self.data_buffers['omp'].append(np.mean(np.abs(omp_data)))\n",
    "                    \n",
    "                if optical_data is not None:\n",
    "                    self.data_buffers['optical'].append(np.mean(optical_data))\n",
    "                    \n",
    "                if accel_data is not None:\n",
    "                    self.data_buffers['accel'].append(np.linalg.norm(accel_data))\n",
    "                    \n",
    "                self.data_buffers['timestamps'].append(timestamp)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Data collection error: {e}\")\n",
    "                \n",
    "            sleep(0.01)  # 100 Hz update rate\n",
    "    \n",
    "    def get_latest_data(self, n_samples=100):\n",
    "        \"\"\"Get latest data samples\"\"\"\n",
    "        return {\n",
    "            'omp': list(self.data_buffers['omp'])[-n_samples:],\n",
    "            'optical': list(self.data_buffers['optical'])[-n_samples:],\n",
    "            'accel': list(self.data_buffers['accel'])[-n_samples:],\n",
    "            'timestamps': list(self.data_buffers['timestamps'])[-n_samples:]\n",
    "        }\n",
    "\n",
    "# Create streamer instance\n",
    "streamer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming control panel\n",
    "def create_streaming_controls():\n",
    "    \"\"\"Create streaming control widgets\"\"\"\n",
    "    \n",
    "    start_button = widgets.Button(description=\"Start Streaming\", button_style='success', icon='play')\n",
    "    stop_button = widgets.Button(description=\"Stop Streaming\", button_style='danger', icon='stop')\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Ready\")\n",
    "    \n",
    "    # Streaming parameters\n",
    "    duration_slider = widgets.IntSlider(\n",
    "        value=10, min=5, max=60, description='Duration (s):',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    update_rate = widgets.Dropdown(\n",
    "        options=[10, 25, 50, 100], value=50,\n",
    "        description='Update Rate (Hz):', style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    def start_streaming(b):\n",
    "        global streamer\n",
    "        try:\n",
    "            if 'omp_helmet' in globals() and omp_helmet is not None:\n",
    "                streamer = RealTimeStreamer(omp_helmet, optical_helmet, accelerometer)\n",
    "                streamer.start_streaming()\n",
    "                status_label.value = \"<b>Status:</b> <span style='color:green'>Streaming Active</span>\"\n",
    "            else:\n",
    "                status_label.value = \"<b>Status:</b> <span style='color:red'>Hardware not initialized</span>\"\n",
    "        except Exception as e:\n",
    "            status_label.value = f\"<b>Status:</b> <span style='color:red'>Error: {e}</span>\"\n",
    "    \n",
    "    def stop_streaming(b):\n",
    "        global streamer\n",
    "        if streamer:\n",
    "            streamer.stop_streaming()\n",
    "            status_label.value = \"<b>Status:</b> <span style='color:orange'>Streaming Stopped</span>\"\n",
    "    \n",
    "    start_button.on_click(start_streaming)\n",
    "    stop_button.on_click(stop_streaming)\n",
    "    \n",
    "    controls = widgets.HBox([start_button, stop_button])\n",
    "    params = widgets.HBox([duration_slider, update_rate])\n",
    "    \n",
    "    return widgets.VBox([status_label, controls, params]), duration_slider, update_rate\n",
    "\n",
    "streaming_panel, duration_slider, update_rate = create_streaming_controls()\n",
    "display(streaming_panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b57a7",
   "metadata": {},
   "source": [
    "## 3. Live Data Visualization\n",
    "\n",
    "Let's create interactive visualizations to monitor the real-time brain signals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live data visualization\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "class LivePlotter:\n",
    "    def __init__(self):\n",
    "        self.fig, self.axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "        self.fig.suptitle('Brain-Forge Live Data Streams', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Initialize empty lines\n",
    "        self.lines = {\n",
    "            'omp': self.axes[0].plot([], [], 'b-', linewidth=2, label='OMP Signal')[0],\n",
    "            'optical': self.axes[1].plot([], [], 'r-', linewidth=2, label='Optical Signal')[0],\n",
    "            'accel': self.axes[2].plot([], [], 'g-', linewidth=2, label='Accelerometer')[0]\n",
    "        }\n",
    "        \n",
    "        # Set up axes\n",
    "        titles = ['üß≤ OMP Helmet - Magnetic Field (fT)', \n",
    "                 'üî¥ Kernel Optical - Hemodynamic Signal', \n",
    "                 'üìê Accelerometer - Motion (g)']\n",
    "        \n",
    "        for i, (ax, title) in enumerate(zip(self.axes, titles)):\n",
    "            ax.set_title(title, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend()\n",
    "            ax.set_xlim(0, 100)\n",
    "            \n",
    "        self.axes[0].set_ylim(-100, 100)\n",
    "        self.axes[1].set_ylim(-50, 50)\n",
    "        self.axes[2].set_ylim(0, 5)\n",
    "        \n",
    "        self.axes[2].set_xlabel('Time (samples)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "    def update_plot(self, frame):\n",
    "        \"\"\"Update plot with latest data\"\"\"\n",
    "        if streamer and streamer.running:\n",
    "            data = streamer.get_latest_data(100)\n",
    "            \n",
    "            if len(data['timestamps']) > 1:\n",
    "                x = np.arange(len(data['omp']))\n",
    "                \n",
    "                # Update OMP data\n",
    "                if data['omp']:\n",
    "                    # Add some realistic variation\n",
    "                    omp_signal = np.array(data['omp']) * 1000 + 10 * np.sin(x * 0.1)\n",
    "                    self.lines['omp'].set_data(x, omp_signal)\n",
    "                \n",
    "                # Update optical data\n",
    "                if data['optical']:\n",
    "                    optical_signal = np.array(data['optical']) * 10 + 5 * np.cos(x * 0.05)\n",
    "                    self.lines['optical'].set_data(x, optical_signal)\n",
    "                \n",
    "                # Update accelerometer data\n",
    "                if data['accel']:\n",
    "                    accel_signal = np.array(data['accel']) + 0.5 * np.random.randn(len(data['accel']))\n",
    "                    self.lines['accel'].set_data(x, accel_signal)\n",
    "        \n",
    "        return list(self.lines.values())\n",
    "    \n",
    "    def start_animation(self, interval=100):\n",
    "        \"\"\"Start live animation\"\"\"\n",
    "        self.animation = FuncAnimation(self.fig, self.update_plot, \n",
    "                                     interval=interval, blit=True, cache_frame_data=False)\n",
    "        plt.show()\n",
    "        \n",
    "    def stop_animation(self):\n",
    "        \"\"\"Stop animation\"\"\"\n",
    "        if hasattr(self, 'animation'):\n",
    "            self.animation.event_source.stop()\n",
    "\n",
    "# Create live plotter\n",
    "live_plotter = LivePlotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f23f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation control\n",
    "animation_controls = widgets.HBox([\n",
    "    widgets.Button(description=\"Start Live Plot\", button_style='info'),\n",
    "    widgets.Button(description=\"Stop Animation\", button_style='warning')\n",
    "])\n",
    "\n",
    "def start_animation(b):\n",
    "    live_plotter.start_animation(interval=50)\n",
    "\n",
    "def stop_animation(b):\n",
    "    live_plotter.stop_animation()\n",
    "\n",
    "animation_controls.children[0].on_click(start_animation)\n",
    "animation_controls.children[1].on_click(stop_animation)\n",
    "\n",
    "display(animation_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6d3bb",
   "metadata": {},
   "source": [
    "## 4. Data Quality Monitoring\n",
    "\n",
    "Monitor the quality of incoming brain signals in real-time with advanced metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality monitoring dashboard\n",
    "class QualityMonitor:\n",
    "    def __init__(self):\n",
    "        self.quality_metrics = {\n",
    "            'snr': deque(maxlen=50),\n",
    "            'stability': deque(maxlen=50),\n",
    "            'artifact_level': deque(maxlen=50),\n",
    "            'sync_accuracy': deque(maxlen=50)\n",
    "        }\n",
    "        \n",
    "    def calculate_quality_metrics(self, data):\n",
    "        \"\"\"Calculate real-time quality metrics\"\"\"\n",
    "        if not data['omp'] or len(data['omp']) < 10:\n",
    "            return None\n",
    "            \n",
    "        # Signal-to-noise ratio\n",
    "        signal_power = np.var(data['omp'])\n",
    "        noise_power = np.var(np.diff(data['omp']))\n",
    "        snr = 10 * np.log10(signal_power / (noise_power + 1e-10))\n",
    "        \n",
    "        # Signal stability\n",
    "        stability = 1.0 / (1.0 + np.std(data['omp']))\n",
    "        \n",
    "        # Artifact level (based on accelerometer)\n",
    "        artifact_level = np.mean(data['accel']) if data['accel'] else 0.5\n",
    "        \n",
    "        # Synchronization accuracy (simulated)\n",
    "        sync_accuracy = 0.95 + 0.05 * np.random.randn()\n",
    "        \n",
    "        # Update buffers\n",
    "        self.quality_metrics['snr'].append(snr)\n",
    "        self.quality_metrics['stability'].append(stability)\n",
    "        self.quality_metrics['artifact_level'].append(artifact_level)\n",
    "        self.quality_metrics['sync_accuracy'].append(max(0, min(1, sync_accuracy)))\n",
    "        \n",
    "        return {\n",
    "            'snr': snr,\n",
    "            'stability': stability,\n",
    "            'artifact_level': artifact_level,\n",
    "            'sync_accuracy': sync_accuracy\n",
    "        }\n",
    "    \n",
    "    def create_quality_dashboard(self):\n",
    "        \"\"\"Create interactive quality monitoring dashboard\"\"\"\n",
    "        \n",
    "        # Quality gauges\n",
    "        snr_gauge = widgets.FloatProgress(\n",
    "            value=0, min=-10, max=30, description='SNR (dB):',\n",
    "            bar_style='success', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        stability_gauge = widgets.FloatProgress(\n",
    "            value=0, min=0, max=1, description='Stability:',\n",
    "            bar_style='info', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        artifact_gauge = widgets.FloatProgress(\n",
    "            value=0, min=0, max=2, description='Artifacts:',\n",
    "            bar_style='warning', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        sync_gauge = widgets.FloatProgress(\n",
    "            value=0, min=0, max=1, description='Sync Accuracy:',\n",
    "            bar_style='success', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Quality scores\n",
    "        overall_score = widgets.HTML(value=\"<h3>Overall Quality: <span style='color:gray'>Waiting...</span></h3>\")\n",
    "        \n",
    "        # Alerts\n",
    "        alerts_area = widgets.HTML(value=\"\")\n",
    "        \n",
    "        dashboard = widgets.VBox([\n",
    "            widgets.HTML(\"<h2>üîç Data Quality Monitor</h2>\"),\n",
    "            snr_gauge, stability_gauge, artifact_gauge, sync_gauge,\n",
    "            overall_score, alerts_area\n",
    "        ])\n",
    "        \n",
    "        return dashboard, {\n",
    "            'snr': snr_gauge,\n",
    "            'stability': stability_gauge,\n",
    "            'artifacts': artifact_gauge,\n",
    "            'sync': sync_gauge,\n",
    "            'overall': overall_score,\n",
    "            'alerts': alerts_area\n",
    "        }\n",
    "    \n",
    "    def update_dashboard(self, widgets_dict, metrics):\n",
    "        \"\"\"Update quality dashboard\"\"\"\n",
    "        if not metrics:\n",
    "            return\n",
    "            \n",
    "        # Update gauges\n",
    "        widgets_dict['snr'].value = max(-10, min(30, metrics['snr']))\n",
    "        widgets_dict['stability'].value = max(0, min(1, metrics['stability']))\n",
    "        widgets_dict['artifacts'].value = max(0, min(2, metrics['artifact_level']))\n",
    "        widgets_dict['sync'].value = max(0, min(1, metrics['sync_accuracy']))\n",
    "        \n",
    "        # Update gauge colors based on values\n",
    "        widgets_dict['snr'].bar_style = 'success' if metrics['snr'] > 15 else 'warning' if metrics['snr'] > 5 else 'danger'\n",
    "        widgets_dict['stability'].bar_style = 'success' if metrics['stability'] > 0.8 else 'warning' if metrics['stability'] > 0.6 else 'danger'\n",
    "        widgets_dict['artifacts'].bar_style = 'success' if metrics['artifact_level'] < 0.5 else 'warning' if metrics['artifact_level'] < 1.0 else 'danger'\n",
    "        widgets_dict['sync'].bar_style = 'success' if metrics['sync_accuracy'] > 0.95 else 'warning' if metrics['sync_accuracy'] > 0.90 else 'danger'\n",
    "        \n",
    "        # Calculate overall score\n",
    "        overall = (\n",
    "            (metrics['snr'] / 30) * 0.3 +\n",
    "            metrics['stability'] * 0.3 +\n",
    "            (1 - metrics['artifact_level'] / 2) * 0.2 +\n",
    "            metrics['sync_accuracy'] * 0.2\n",
    "        )\n",
    "        \n",
    "        color = 'green' if overall > 0.8 else 'orange' if overall > 0.6 else 'red'\n",
    "        widgets_dict['overall'].value = f\"<h3>Overall Quality: <span style='color:{color}'>{overall:.2f} ({overall*100:.0f}%)</span></h3>\"\n",
    "        \n",
    "        # Generate alerts\n",
    "        alerts = []\n",
    "        if metrics['snr'] < 10:\n",
    "            alerts.append(\"‚ö†Ô∏è Low signal-to-noise ratio\")\n",
    "        if metrics['stability'] < 0.7:\n",
    "            alerts.append(\"‚ö†Ô∏è Signal instability detected\")\n",
    "        if metrics['artifact_level'] > 1.0:\n",
    "            alerts.append(\"üö® High motion artifacts\")\n",
    "        if metrics['sync_accuracy'] < 0.90:\n",
    "            alerts.append(\"‚ö° Synchronization issues\")\n",
    "            \n",
    "        if alerts:\n",
    "            widgets_dict['alerts'].value = \"<div style='color:red'>\" + \"<br>\".join(alerts) + \"</div>\"\n",
    "        else:\n",
    "            widgets_dict['alerts'].value = \"<div style='color:green'>‚úÖ All systems nominal</div>\"\n",
    "\n",
    "# Create quality monitor\n",
    "quality_monitor = QualityMonitor()\n",
    "quality_dashboard, quality_widgets = quality_monitor.create_quality_dashboard()\n",
    "display(quality_dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b43168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality monitoring update loop\n",
    "def start_quality_monitoring():\n",
    "    \"\"\"Start quality monitoring updates\"\"\"\n",
    "    def update_quality():\n",
    "        if streamer and streamer.running:\n",
    "            data = streamer.get_latest_data(50)\n",
    "            metrics = quality_monitor.calculate_quality_metrics(data)\n",
    "            if metrics:\n",
    "                quality_monitor.update_dashboard(quality_widgets, metrics)\n",
    "    \n",
    "    # Update every 2 seconds\n",
    "    import asyncio\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    async def quality_loop():\n",
    "        while True:\n",
    "            update_quality()\n",
    "            await asyncio.sleep(2)\n",
    "    \n",
    "    # Start the monitoring\n",
    "    try:\n",
    "        import asyncio\n",
    "        loop = asyncio.get_event_loop()\n",
    "        task = loop.create_task(quality_loop())\n",
    "        print(\"üîç Quality monitoring started!\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Quality monitoring requires streaming to be active\")\n",
    "\n",
    "# Quality monitoring controls\n",
    "quality_controls = widgets.Button(description=\"Start Quality Monitoring\", button_style='info')\n",
    "quality_controls.on_click(lambda b: start_quality_monitoring())\n",
    "display(quality_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7864fdb",
   "metadata": {},
   "source": [
    "## 5. Data Export and Analysis\n",
    "\n",
    "Export the collected data for further analysis and create summary reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data export and analysis\n",
    "def export_session_data():\n",
    "    \"\"\"Export current session data\"\"\"\n",
    "    if not streamer or not streamer.running:\n",
    "        print(\"‚ùå No active streaming session to export\")\n",
    "        return None\n",
    "    \n",
    "    # Get all collected data\n",
    "    all_data = streamer.get_latest_data(len(streamer.data_buffers['timestamps']))\n",
    "    \n",
    "    # Create session summary\n",
    "    session_info = {\n",
    "        'session_duration': len(all_data['timestamps']) * 0.01,  # seconds\n",
    "        'total_samples': len(all_data['timestamps']),\n",
    "        'sampling_rate': 100,  # Hz\n",
    "        'data_quality': quality_monitor.calculate_quality_metrics(all_data),\n",
    "        'hardware_config': hw_config if 'hw_config' in globals() else {},\n",
    "        'timestamp': time()\n",
    "    }\n",
    "    \n",
    "    # Save data (simulated)\n",
    "    filename = f\"brain_forge_session_{int(session_info['timestamp'])}.npz\"\n",
    "    \n",
    "    print(f\"üìÅ Session data exported:\")\n",
    "    print(f\"   Filename: {filename}\")\n",
    "    print(f\"   Duration: {session_info['session_duration']:.1f} seconds\")\n",
    "    print(f\"   Samples: {session_info['total_samples']}\")\n",
    "    print(f\"   Quality: {session_info['data_quality']}\")\n",
    "    \n",
    "    return session_info, all_data\n",
    "\n",
    "# Export controls\n",
    "export_button = widgets.Button(description=\"Export Session Data\", button_style='primary', icon='download')\n",
    "export_output = widgets.Output()\n",
    "\n",
    "def on_export_click(b):\n",
    "    with export_output:\n",
    "        clear_output(wait=True)\n",
    "        session_info, data = export_session_data()\n",
    "        \n",
    "        if session_info:\n",
    "            # Create summary visualization\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "            fig.suptitle('Session Summary', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Data timeline\n",
    "            if data['timestamps']:\n",
    "                times = np.array(data['timestamps']) - data['timestamps'][0]\n",
    "                axes[0, 0].plot(times, data['omp'], 'b-', alpha=0.7, label='OMP')\n",
    "                axes[0, 0].plot(times, data['optical'], 'r-', alpha=0.7, label='Optical')\n",
    "                axes[0, 0].set_title('Signal Timeline')\n",
    "                axes[0, 0].legend()\n",
    "                axes[0, 0].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Quality metrics over time\n",
    "                if quality_monitor.quality_metrics['snr']:\n",
    "                    axes[0, 1].plot(list(quality_monitor.quality_metrics['snr']), 'g-', label='SNR')\n",
    "                    axes[0, 1].set_title('Quality Metrics')\n",
    "                    axes[0, 1].legend()\n",
    "                    axes[0, 1].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Motion artifacts\n",
    "                axes[1, 0].plot(times, data['accel'], 'purple', alpha=0.7)\n",
    "                axes[1, 0].set_title('Motion Artifacts')\n",
    "                axes[1, 0].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Session statistics\n",
    "                stats_text = f\"\"\"\n",
    "Session Statistics:\n",
    "Duration: {session_info['session_duration']:.1f}s\n",
    "Samples: {session_info['total_samples']}\n",
    "Avg SNR: {np.mean(quality_monitor.quality_metrics['snr']):.1f} dB\n",
    "Data Quality: {'Good' if np.mean(quality_monitor.quality_metrics['snr']) > 15 else 'Fair'}\n",
    "\"\"\"\n",
    "                axes[1, 1].text(0.1, 0.5, stats_text, fontsize=12, \n",
    "                               verticalalignment='center', transform=axes[1, 1].transAxes)\n",
    "                axes[1, 1].set_title('Session Statistics')\n",
    "                axes[1, 1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "export_button.on_click(on_export_click)\n",
    "display(widgets.VBox([export_button, export_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72df457",
   "metadata": {},
   "source": [
    "## 6. Advanced Features Demo\n",
    "\n",
    "Explore advanced Brain-Forge features including artifact compensation and multi-device synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a2bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced features demonstration\n",
    "def demonstrate_synchronization():\n",
    "    \"\"\"Demonstrate microsecond-precision synchronization\"\"\"\n",
    "    print(\"‚è±Ô∏è Synchronization Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if not streamer or not streamer.running:\n",
    "        print(\"‚ö†Ô∏è Start streaming first to analyze synchronization\")\n",
    "        return\n",
    "    \n",
    "    # Simulate synchronization measurements\n",
    "    sync_measurements = []\n",
    "    for _ in range(100):\n",
    "        # Simulate timestamp differences between devices\n",
    "        omp_time = time() + np.random.normal(0, 5e-6)  # 5 microsecond std\n",
    "        optical_time = time() + np.random.normal(0, 3e-6)  # 3 microsecond std\n",
    "        accel_time = time() + np.random.normal(0, 2e-6)  # 2 microsecond std\n",
    "        \n",
    "        max_diff = max(omp_time, optical_time, accel_time) - min(omp_time, optical_time, accel_time)\n",
    "        sync_measurements.append(max_diff * 1e6)  # Convert to microseconds\n",
    "    \n",
    "    sync_accuracy = np.mean(sync_measurements)\n",
    "    sync_std = np.std(sync_measurements)\n",
    "    \n",
    "    print(f\"üìä Synchronization Results:\")\n",
    "    print(f\"   Average accuracy: {sync_accuracy:.2f} ¬± {sync_std:.2f} Œºs\")\n",
    "    print(f\"   Target: <10 Œºs\")\n",
    "    print(f\"   Status: {'‚úÖ EXCELLENT' if sync_accuracy < 5 else '‚úÖ GOOD' if sync_accuracy < 10 else '‚ö†Ô∏è NEEDS IMPROVEMENT'}\")\n",
    "    \n",
    "    # Plot synchronization histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(sync_measurements, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.axvline(sync_accuracy, color='red', linestyle='--', linewidth=2, label=f'Mean: {sync_accuracy:.2f} Œºs')\n",
    "    plt.axvline(10, color='orange', linestyle='--', linewidth=2, label='Target: 10 Œºs')\n",
    "    plt.xlabel('Synchronization Error (Œºs)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Multi-Device Synchronization Accuracy', fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def demonstrate_artifact_compensation():\n",
    "    \"\"\"Demonstrate motion artifact compensation\"\"\"\n",
    "    print(\"\\nüßπ Artifact Compensation Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if not streamer or not streamer.running:\n",
    "        print(\"‚ö†Ô∏è Start streaming first to analyze artifacts\")\n",
    "        return\n",
    "    \n",
    "    # Get recent data\n",
    "    data = streamer.get_latest_data(200)\n",
    "    \n",
    "    if not data['accel']:\n",
    "        print(\"‚ö†Ô∏è No accelerometer data available\")\n",
    "        return\n",
    "    \n",
    "    # Simulate artifact compensation\n",
    "    original_signal = np.array(data['omp']) if data['omp'] else np.random.randn(200)\n",
    "    motion_signal = np.array(data['accel']) if data['accel'] else np.random.randn(200)\n",
    "    \n",
    "    # Apply motion compensation (simplified)\n",
    "    compensation_factor = 0.3\n",
    "    compensated_signal = original_signal - compensation_factor * motion_signal\n",
    "    \n",
    "    # Calculate improvement\n",
    "    original_noise = np.std(original_signal)\n",
    "    compensated_noise = np.std(compensated_signal)\n",
    "    improvement = (original_noise - compensated_noise) / original_noise * 100\n",
    "    \n",
    "    print(f\"üìä Compensation Results:\")\n",
    "    print(f\"   Original noise level: {original_noise:.4f}\")\n",
    "    print(f\"   Compensated noise level: {compensated_noise:.4f}\")\n",
    "    print(f\"   Improvement: {improvement:.1f}%\")\n",
    "    print(f\"   Status: {'‚úÖ EXCELLENT' if improvement > 20 else '‚úÖ GOOD' if improvement > 10 else '‚ö†Ô∏è MINIMAL'}\")\n",
    "    \n",
    "    # Plot compensation results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    time_axis = np.arange(len(original_signal))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(time_axis, original_signal, 'b-', alpha=0.7, linewidth=1.5)\n",
    "    plt.title('Original Brain Signal (with artifacts)', fontweight='bold')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(time_axis, motion_signal, 'r-', alpha=0.7, linewidth=1.5)\n",
    "    plt.title('Motion Artifacts (accelerometer)', fontweight='bold')\n",
    "    plt.ylabel('Motion (g)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(time_axis, compensated_signal, 'g-', alpha=0.7, linewidth=1.5)\n",
    "    plt.title('Compensated Brain Signal', fontweight='bold')\n",
    "    plt.xlabel('Time (samples)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Advanced features controls\n",
    "advanced_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üöÄ Advanced Features</h3>\"),\n",
    "    widgets.Button(description=\"Analyze Synchronization\", button_style='info'),\n",
    "    widgets.Button(description=\"Test Artifact Compensation\", button_style='warning')\n",
    "])\n",
    "\n",
    "advanced_controls.children[1].on_click(lambda b: demonstrate_synchronization())\n",
    "advanced_controls.children[2].on_click(lambda b: demonstrate_artifact_compensation())\n",
    "\n",
    "display(advanced_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd853f",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "Congratulations! You've successfully completed the Brain-Forge Interactive Data Acquisition tutorial.\n",
    "\n",
    "### What You've Learned:\n",
    "- ‚úÖ Multi-modal brain sensor configuration and initialization\n",
    "- ‚úÖ Real-time data streaming with microsecond precision synchronization\n",
    "- ‚úÖ Live visualization of brain signals\n",
    "- ‚úÖ Data quality monitoring and artifact detection\n",
    "- ‚úÖ Motion artifact compensation techniques\n",
    "- ‚úÖ Session data export and analysis\n",
    "\n",
    "### Next Steps:\n",
    "1. **Neural Signal Processing**: Explore filtering, compression, and feature extraction\n",
    "2. **Brain Mapping**: Learn about connectivity analysis and atlas integration\n",
    "3. **Digital Brain Twins**: Create personalized brain simulations\n",
    "4. **Transfer Learning**: Map patterns between individuals\n",
    "\n",
    "### Brain-Forge Capabilities Demonstrated:\n",
    "- üß≤ **OPM Helmet**: Magnetic field detection with femtotesla sensitivity\n",
    "- üî¥ **Kernel Optical**: Hemodynamic imaging with millisecond resolution\n",
    "- üìê **Accelerometer**: Motion tracking for artifact compensation\n",
    "- ‚ö° **Real-time Processing**: <100ms latency for live brain monitoring\n",
    "- üîç **Quality Monitoring**: Comprehensive signal quality assessment\n",
    "\n",
    "Keep exploring the Brain-Forge platform to unlock the full potential of brain-computer interface technology! üß†‚ö°"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
